{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd32800-069e-4a31-9719-de94a3e1ee06",
   "metadata": {},
   "source": [
    "# 5 Computational Performance: GraphFrames vs igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d99db-af37-4e6b-be65-6f27540e36aa",
   "metadata": {},
   "source": [
    "## 5.0.1 Introduction and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5d4d76-2443-4c3d-b3f7-801fc2ebb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60263bab-7e85-4297-a27e-2357e6106d98",
   "metadata": {},
   "source": [
    "Since the test runtimes were conducted on different machines and in different environments (R igraph running locally on Device A, Scala GraphFrames running on a Virtual Machine on Device B), the saved runtimes that we had are difficult to compare effectively. This section of the report focuses on using PySpark GraphFrames (run on Jupyter Lab on Device C) to compare with igraph also run on Jupyter Lab on Device C. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447574f-57f4-4096-83f1-7dd3ac1f2155",
   "metadata": {},
   "source": [
    "However, before jumping into runtimes, we briefly explore how the GraphFrame module works with PySpark and develop understanding of how our graphs are constructed to run our algorithms on.\n",
    "\n",
    "Note: If you run this code and want to keep comparing runtimes as on your own machine, you will need to run the code in the Appendix first. The section where this becomes particularly relevant is highlighted later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9a3cda-7546-418d-ad87-df2fe1994221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise sparkContext and set checkpoint \n",
    "sc = spark.sparkContext\n",
    "sc.setCheckpointDir('times_cps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd77957-ebd0-472d-ab16-562552db2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of nodes that correspond to our ER graphs\n",
    "nodes = [10,32, 100, 316, 1000, 3162, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b20b7d9c-d6a5-46b7-b45e-76facdc017f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 1\n",
      "32 2\n",
      "100 1\n",
      "316 2\n",
      "1000 1\n",
      "3162 2\n",
      "10000 1\n",
      "10 2\n",
      "32 1\n",
      "100 2\n",
      "316 1\n",
      "1000 2\n",
      "3162 1\n",
      "10000 2\n"
     ]
    }
   ],
   "source": [
    "#we check if this zip method works for printing our number of nodes\n",
    "#and zipping 1 and 2 to each node\n",
    "for n,i in list(zip(2*nodes, [1,2]*len(nodes)*2)):\n",
    "    print(n,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b8c57-c2d6-4cf5-80f2-594e3e8a0cc9",
   "metadata": {},
   "source": [
    "## 5.0.2 Loading in Graph Connection CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d78c39-35b0-4d40-bc3b-9bea31740fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe for edge counts\n",
    "edge_df = pd.DataFrame(columns=['p1','p2'],index=nodes)\n",
    "edge_df.index.name = 'nodes'\n",
    "\n",
    "#created our zipped list as above and loop through it\n",
    "for n,i in list(zip(2*nodes, [1,2]*len(nodes)*2)):\n",
    "    #set path to grab correct edges csv e.g. 'G_ 100 _p1'\n",
    "    path = '../Data/G_ ' + str(n) + ' _p' + str(i)\n",
    "    edges = spark.read.csv(path,header=True)\n",
    "    #rename to match the 'src' and 'dst format that spark prefers, drop index col '_c0'\n",
    "    edges = edges.withColumnRenamed('V1','src').withColumnRenamed('V2','dst').drop('_c0')\n",
    "    #create a list of ids; these are the vertices for our erdos-renyi graphs\n",
    "    ids = list(range(1,n+1))\n",
    "    #assign vertices to ids\n",
    "    vertices = spark.createDataFrame(ids, IntegerType()).withColumnRenamed('value','id')\n",
    "    #store above variables under appropriate name, e.g. p1_10_e for G_10_p1 edges etc\n",
    "    locals()['p{}_{}_e'.format(i,n)] = edges\n",
    "    locals()['p{}_{}_v'.format(i,n)] = vertices\n",
    "    \n",
    "    #retrieve edge count and assign it to dataframe\n",
    "    edge_df.loc[n][i-1] = edges.count()\n",
    "    \n",
    "    \n",
    "#delete our temp vars\n",
    "del edges\n",
    "del ids\n",
    "del vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6b4ea-5e93-41bd-9e5a-5cf8d9ddaed6",
   "metadata": {},
   "source": [
    "We take a look at our edge_df dataframe below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fec1007-5e01-4b84-972c-edf7f2e3c0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>225</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>777</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>3105</td>\n",
       "      <td>3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>11479</td>\n",
       "      <td>13918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>41996</td>\n",
       "      <td>50201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p1     p2\n",
       "nodes              \n",
       "10         4     13\n",
       "32        42     59\n",
       "100      225    233\n",
       "316      777   1021\n",
       "1000    3105   3780\n",
       "3162   11479  13918\n",
       "10000  41996  50201"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580003b0-12c3-41e3-8964-5b0d018c2125",
   "metadata": {},
   "source": [
    "## 5.0.3 Constructing Graphs and Checking Implementation with GraphFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d14e7a-b343-434e-b81f-62e1c7af012e",
   "metadata": {},
   "source": [
    "We now preview our edges and vertices spark dataframes before constructing graphs objects out of them. We plot the graphs and we perform sanity checks to see that our GraphFrame implementation is running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b3ad956-84b8-47ca-bb38-b2327f990479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preview vertices for graph with 10 nodes and connection prob p1=0.15\n",
    "p1_10_v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "826ed47e-d692-4893-9e46-dbc7ae34e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  1|  5|\n",
      "|  2|  5|\n",
      "|  3|  8|\n",
      "|  7| 10|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#preview edges \n",
    "p1_10_e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "943b9ccf-18c0-452b-b435-5b8f6630d4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|component|\n",
      "+---+---------+\n",
      "|  1|        1|\n",
      "|  2|        1|\n",
      "|  3|        3|\n",
      "|  4|        4|\n",
      "|  5|        1|\n",
      "|  6|        6|\n",
      "|  7|        7|\n",
      "|  8|        3|\n",
      "|  9|        9|\n",
      "| 10|        7|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create g1_10 corresponding to the p1_10 vertices/edges framework above \n",
    "g1_10 = GraphFrame(v=p1_10_v, e=p1_10_e)\n",
    "#find what components/communities each vertex/node belongs in\n",
    "g1_10.connectedComponents().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c354e-75c3-41ff-9fa3-8ab416bc3f6c",
   "metadata": {},
   "source": [
    "Having constructed our graph above, we now calculate the number of components in the graph to see if it is connected or not (if number of components == 1, then the graph is fully connected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c28979f-b659-4d04-89b7-1f946e376284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculating num of communities\n",
    "#this is in a separate cell so that the magic %%time function in the next cell works correctly\n",
    "def countComps(graph):\n",
    "    return graph.connectedComponents().select('component').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8591c0d4-087a-4702-909e-e946cc754b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#select the 'component' column above and count distinct elements\n",
    "#this is what we want to measure the time performance of\n",
    "countComps(g1_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a593028-3f7b-4dc0-92d3-c9725f79cb07",
   "metadata": {},
   "source": [
    "We seem to have 6 connected communities in this particular graph. We plot the graph as a sanity check to confirm this and everything else that we saw previously. The code from this is adapted from this [stackoverflow post](https://stackoverflow.com/questions/54204062/how-to-display-visualize-a-graph-created-by-graphframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c7d4d4b-6369-4d80-90c7-850fd28d35c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define plotting function\n",
    "def PlotGraph(edge_list):\n",
    "    Gplot=nx.Graph()\n",
    "    for row in edge_list.select('src','dst').take(212384):\n",
    "        Gplot.add_edge(row['src'],row['dst'])\n",
    "\n",
    "        \n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    nx.draw(Gplot, with_labels=True, font_weight='bold')\n",
    "\n",
    "#plot graph\n",
    "PlotGraph(g1_10.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4eb228-c770-42c5-869a-0249807d0258",
   "metadata": {},
   "source": [
    "As we can see, there are 3 communities over 7 of our vertices. However, that means 3 of our vertices are not connected to any other vertices, therefore, they form their own communities. This gives us a total of 6 connected components as we found above.\n",
    "\n",
    "We further look at number of edges to check that this is working as intended. We do not check number of vertices because we have explicitly constructed these, whereas edges were random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07774ce3-f4ed-43b8-8c11-16a0abd5481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.loc[10][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ae662-885a-41c0-9f17-4f7f8bca7e78",
   "metadata": {},
   "source": [
    "Now we create all the remaining graphs and run our countComps function on them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0704d057-d5f6-424b-9fe0-4e3695fab6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over (nodes,[1,2]) to create respective graphs\n",
    "for n,i in list(zip(2*nodes, [1,2]*len(nodes)*2)):\n",
    "    edges = locals()['p{}_{}_e'.format(i,n)]\n",
    "    vertices = locals()['p{}_{}_v'.format(i,n)]\n",
    "    #assign graphframe object to appropriately named variable\n",
    "    locals()['g{}_{}'.format(i,n)] = GraphFrame(v=vertices,e=edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2456e-385e-473f-b942-c7ee6e2a40d0",
   "metadata": {},
   "source": [
    "## 5.0.4 Calculating PySpark Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad4c4a-c7fe-4447-9494-9d2a416a895c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5.0.4.1 All Runtimes in Single Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6b3e8-f121-4666-908c-0ab20aaf5cab",
   "metadata": {},
   "source": [
    "Here, we try to time all our runtimes at once in this same single Notebook. Without jumping ahead too much, we mention now that this did not work too well.\n",
    "\n",
    "For time recording of the functions, we use `%timeit%` instead of `%%time` so that we can store the results.\n",
    "\n",
    "One thing that needs to be pointed out here, though, is that as the kernel runs for longer and more variables are stored, the runtimes seem to increase. What the main driver is for this (number of runs already made; number of variabless saved; or something else) is not something that we have clarified, but it's also something that's outside of the scope of this work. It suffices to note that the same function run on the same graph (in this case `countComps(g1_10)` typically takes 10-11s on initial runs but after multiple changes and cells run, this can take up to 34-36s. We did not try actively to keep recreating this and to find out the reason for it as there was not enough time to do so.\n",
    "\n",
    "However, we do not just brush this off as, in a realistic scenario, if we had to run multiple graph analyses this issue would persist and so we keep it here since we did the same for R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236b663-b3d5-42d9-b452-ae062d1e9b3e",
   "metadata": {},
   "source": [
    "We loop over all our graphs below and count the number of communities in each, storing the runtime required for these computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203faeb-c834-49b9-8fdb-73bda22ff9ca",
   "metadata": {},
   "source": [
    "We ran the code below to calculate and store our runtimes but an error is thrown back to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d8cb55-48bf-4e47-b0db-7ebf6710431f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #loop to record times\n",
    "# for n,i in list(zip(2*nodes, [1,2]*len(nodes)*2)):\n",
    "#     graph = locals()['g{}_{}'.format(i,n)]\n",
    "#     #run for 2 loops (-n2), 2 runs (-r2), and save results (-o)\n",
    "#     result = %timeit -n2 -r2 -o countComps(graph)\n",
    "#     locals()['r{}_{}'.format(i,n)] = result\n",
    "    \n",
    "#     del result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c082dd-852a-4edb-b4dc-506952dfba6d",
   "metadata": {},
   "source": [
    "> `11.2 s ± 267 ms per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`15.2 s ± 824 ms per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`20.6 s ± 1.44 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`23.9 s ± 2.3 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`28.3 s ± 4.24 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`35 s ± 7.48 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`1min ± 15.4 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`12.1 s ± 837 ms per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`19.6 s ± 606 ms per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`22.3 s ± 1.5 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`58.8 s ± 6.5 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`1min 12s ± 7.14 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`2min 27s ± 2.89 s per loop (mean ± std. dev. of 2 runs, 2 loops each)`<br>\n",
    "`ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b55eb2-353c-4698-a208-8ad446a9b6b7",
   "metadata": {},
   "source": [
    "This is the corresponding error: annoyingly 13 out of the 14 results run before running a *WinError 10054* which according to this [stackoverflow post](https://stackoverflow.com/questions/8814802/python-errno-10054-an-existing-connection-was-forcibly-closed-by-the-remote-h) results from a server closing due to long runtime. This seems to be more related to apache.spark than anything in our case and retrying/restarting the connection did not work for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab909e17-b935-4644-8ed9-a1a2e1a6d810",
   "metadata": {},
   "source": [
    "Below we try to view the results and see what result is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2ee7e88-8a1a-4b3f-b17a-671d9333fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error var 'r1_10'\n",
      "Error var 'r2_32'\n",
      "Error var 'r1_100'\n",
      "Error var 'r2_316'\n",
      "Error var 'r1_1000'\n",
      "Error var 'r2_3162'\n",
      "Error var 'r1_10000'\n",
      "Error var 'r2_10'\n",
      "Error var 'r1_32'\n",
      "Error var 'r2_100'\n",
      "Error var 'r1_316'\n",
      "Error var 'r2_1000'\n",
      "Error var 'r1_3162'\n",
      "Error var 'r2_10000'\n"
     ]
    }
   ],
   "source": [
    "for n,i in list(zip(2*nodes, [1,2]*len(nodes)*2)):\n",
    "    try:\n",
    "        print(locals()['r{}_{}'.format(i,n)])\n",
    "    except Exception as e:\n",
    "        print('Error var',e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beefb02d-c683-40e7-ab9e-a8708b2d9f61",
   "metadata": {},
   "source": [
    "If we try running just the code below for this time alone, we get a similar but related error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d641217-b897-4e7b-a622-cb4e2ef4f3cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# r2_10000 = %timeit -n2 -r2 -o countComps(g2_10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e828b7-3c10-44a7-b915-44130343bfcf",
   "metadata": {},
   "source": [
    ">`[WinError 10061] No connection could be made because the target machine actively refused it`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccbbfc-5e5f-4136-a3bc-236feac0f07a",
   "metadata": {},
   "source": [
    "We decide that it's probably best to calculate runtimes in individual Notebooks and save outputs as CSV to compare together here. So we take that approach and we leave the notebooks in the Appendix as it is almost identical to the code above with the exception or running for `p1` in one Notebook and running for `p2` in the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4607a2-f212-4314-a641-d65d7c6f07d4",
   "metadata": {},
   "source": [
    "Instead, we extract the mean and standard deviations of our times in a list to create a DataFrame so that we can store and save what the results were for this attempt for later comparison with the individual notebook runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d398ef-7aed-47db-822c-7be0cb44da9b",
   "metadata": {},
   "source": [
    "The code below relies on running the above code, facing the error, then running this upcoming code to save a dataframe, then restarting kernel. Overall, this is a hassle for the reader and so instead we comment it out and supply the relevant `partial_times.csv` in `../Data/partial_times.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6bc735-1876-4b42-8087-40dfb4c7dd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_lst = []\n",
    "# for n,i in list(zip(2*nodes, [1,2]*len(nodes)*2)):\n",
    "#     try:\n",
    "#         times_lst.append((i,n, str(locals()['r{}_{}'.format(i,n)])))\n",
    "#     except: #skip r2_10000\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e438038b-532e-4297-8f7d-d0edc0783c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #preview of single entry to get an idea of the output\n",
    "# times_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14779e46-bb7e-4551-a097-3ebd0503f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function to extract mean\n",
    "# def getMean(ts):\n",
    "#     splt =  ts.split('±')[0].split(' ')[0:2]\n",
    "#     #if time in seconds, we dont need to do anything \n",
    "#     if splt[1] == 's':\n",
    "#         time = splt[0]\n",
    "#         return time \n",
    "#     else: #if time is 1min 10s for example\n",
    "#         mins = splt[0][0] #take the number before 'min'\n",
    "#         try: #in case full minutes e.g. 1min and no seconds\n",
    "#             secs = float(splt[1][:-1]) #take everything except the 's'\n",
    "#         except:\n",
    "#             secs = 0\n",
    "#         time = int(mins)*60 + int(secs) #convert to seconds\n",
    "#         return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867d23cf-c118-4239-aa5f-5d9a16de4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #code to get standard deviation\n",
    "# def getSD(ts):\n",
    "#     splt = ts.split('±')[1].split(' ')[1:3]\n",
    "#     if splt[1] == 'ms':\n",
    "#         #convert ms to s\n",
    "#         time = float(splt[0])/1000\n",
    "#         return time\n",
    "#     else:\n",
    "#         time = splt[0]\n",
    "#         return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21e28be2-e461-4cf7-9f49-3c1d2ee367c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_dict = {}\n",
    "# times_dict['p'] = [i for i,n,ts in times_lst]\n",
    "# times_dict['nodes'] = [n for i,n,ts in times_lst]\n",
    "# times_dict['mean'] = [getMean(ts) for i,n,ts in times_lst]\n",
    "# times_dict['sd'] = [getSD(ts) for i,n,ts in times_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f47172a-a4ad-407f-9d97-f1dbb76bf634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_df = pd.DataFrame(data=times_dict)\n",
    "# times_df.sort_values(by=['p','nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87513975-8f09-4549-845d-69e8bbbd9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times_df.to_csv('../Data/partial_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9c56109-c099-4c09-8df4-d5369f44409a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>58.8</td>\n",
       "      <td>6.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>28.3</td>\n",
       "      <td>4.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3162</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>22.3</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3162</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p  nodes   mean      sd\n",
       "0   1     10   11.2   0.267\n",
       "1   1     32   19.6   0.606\n",
       "2   1    100   20.6   1.440\n",
       "3   1    316   58.8   6.500\n",
       "4   1   1000   28.3   4.240\n",
       "5   1   3162  147.0   2.890\n",
       "6   1  10000   60.0  15.400\n",
       "7   2     10   12.1   0.837\n",
       "8   2     32   15.2   0.824\n",
       "9   2    100   22.3   1.500\n",
       "10  2    316   23.9   2.300\n",
       "11  2   1000   72.0   7.140\n",
       "12  2   3162   35.0   7.480"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load in times from running in single notebook\n",
    "times_df = pd.read_csv('../Data/partial_times.csv',index_col='Unnamed: 0')\n",
    "times_df = times_df.sort_values(['p','nodes']).reset_index().drop('index',axis=1)\n",
    "times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8a68f-56d9-4f40-8a93-c4dd6bce0c35",
   "metadata": {},
   "source": [
    "### 5.0.4.2 Runtimes in Separate Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08660ed-718f-4fc4-b3f7-4716f9790cb9",
   "metadata": {},
   "source": [
    "##### IMPORTANT: IF YOU WANT TO COMPARE RUNTIME ON YOUR OWN MACHINE, RUN THE CODE IN THE APPENDIX FIRST BEFORE RUNNING THIS SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e85afe-c9de-4402-82a3-26ac898b0619",
   "metadata": {},
   "source": [
    "As mentioned above, we ran the above code (calculating runtimes and then extracting mean and sd to append to DataFrame) in separate notebooks to attain runtimes for the graphs with probabilities `p1` and `p2` one at a time. As these were fresh notebooks, we tried to see what would happen if we calculated runtime over a different number of loops and runs through our `%timeit -nL -rR -o` function (where L and R are the respective number of loops).  \n",
    "\n",
    "We started with the same L=2, R=2 which worked fine. After that, we took an ambitious attempt at L=10, R=3 which caused the same crash somewhere between calculating runtime for the 2nd and 3rd graph. We retried with different numbers but the highest we got it to work with was L=3, R=2.\n",
    "\n",
    "We import the results for L=2, R=2 below as these are more comparable to what we found in this notebook and we make comparison remarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf014f1-5441-4908-9793-6699430c5aaf",
   "metadata": {},
   "source": [
    "#### Import Component Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a0cc60-7ba2-4c7a-be6e-ff619037f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   p  nodes  mean     sd\n",
       " 0  1     10  13.2   2.53\n",
       " 1  1     32  18.3   1.13\n",
       " 2  1    100  21.1   1.18\n",
       " 3  1    316  24.2   2.44\n",
       " 4  1   1000  25.9   2.86\n",
       " 5  1   3162  38.4   6.06\n",
       " 6  1  10000  58.4  15.40,\n",
       "    p  nodes  mean     sd\n",
       " 0  2     10  13.1   2.36\n",
       " 1  2     32  14.5   1.12\n",
       " 2  2    100  20.1   1.39\n",
       " 3  2    316  23.1   2.73\n",
       " 4  2   1000  26.7   3.00\n",
       " 5  2   3162  33.1   7.06\n",
       " 6  2  10000  60.0  16.60]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_times_df_1 = pd.read_csv('../Data/p1_times_1.csv',index_col='Unnamed: 0')\n",
    "p2_times_df_1 = pd.read_csv('../Data/p2_times_1.csv',index_col='Unnamed: 0')\n",
    "\n",
    "data_1 = [p1_times_df_1, p2_times_df_1]\n",
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae98b1-8d28-4501-9f08-9b628519e289",
   "metadata": {},
   "source": [
    "We now edit and merge our imported DataFrames so they have the same structure as our original `times_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10590e98-8e6b-4c5b-a789-1de0ba243812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p  nodes  mean    sd\n",
       "0  1     10  13.2  2.53\n",
       "1  1     32  18.3  1.13\n",
       "2  1    100  21.1  1.18\n",
       "3  1    316  24.2  2.44\n",
       "4  1   1000  25.9  2.86"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_df_1 = pd.concat(data_1,ignore_index=True,sort=False)\n",
    "times_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d322885f-2757-4df4-baa9-6ca9b93e3cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>sd_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>sd_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.53</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.13</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.18</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.44</td>\n",
       "      <td>58.8</td>\n",
       "      <td>6.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2.86</td>\n",
       "      <td>28.3</td>\n",
       "      <td>4.240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p  nodes  mean_x  sd_x  mean_y   sd_y\n",
       "0  1     10    13.2  2.53    11.2  0.267\n",
       "1  1     32    18.3  1.13    19.6  0.606\n",
       "2  1    100    21.1  1.18    20.6  1.440\n",
       "3  1    316    24.2  2.44    58.8  6.500\n",
       "4  1   1000    25.9  2.86    28.3  4.240"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we merge on times_df_1 as it has more rows\n",
    "comp_df = times_df_1.merge(times_df,how='left',left_on=['p','nodes'],right_on=['p','nodes'])\n",
    "comp_df = comp_df.astype({'mean_x':'float','mean_y':'float'})\n",
    "comp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b295cbf3-052c-4a9c-8172-5f3397205713",
   "metadata": {},
   "source": [
    "Note, here we have mean_x corresponding to the mean runtime from the separate notebooks method, while mean_y corresponds to the mean runtime single notebook method. We subtract these columns so that we can look at a meaningful comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5084b28f-3051-4595-b1bd-c4e572ab63b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>sd_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>sd_y</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.53</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.267</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.13</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.18</td>\n",
       "      <td>20.6</td>\n",
       "      <td>1.440</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.44</td>\n",
       "      <td>58.8</td>\n",
       "      <td>6.500</td>\n",
       "      <td>-34.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2.86</td>\n",
       "      <td>28.3</td>\n",
       "      <td>4.240</td>\n",
       "      <td>-2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3162</td>\n",
       "      <td>38.4</td>\n",
       "      <td>6.06</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2.890</td>\n",
       "      <td>-108.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>58.4</td>\n",
       "      <td>15.40</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.400</td>\n",
       "      <td>-1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.36</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.12</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>22.3</td>\n",
       "      <td>1.500</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.73</td>\n",
       "      <td>23.9</td>\n",
       "      <td>2.300</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>26.7</td>\n",
       "      <td>3.00</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.140</td>\n",
       "      <td>-45.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3162</td>\n",
       "      <td>33.1</td>\n",
       "      <td>7.06</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.480</td>\n",
       "      <td>-1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p  nodes  mean_x   sd_x  mean_y    sd_y   diff\n",
       "0   1     10    13.2   2.53    11.2   0.267    2.0\n",
       "1   1     32    18.3   1.13    19.6   0.606   -1.3\n",
       "2   1    100    21.1   1.18    20.6   1.440    0.5\n",
       "3   1    316    24.2   2.44    58.8   6.500  -34.6\n",
       "4   1   1000    25.9   2.86    28.3   4.240   -2.4\n",
       "5   1   3162    38.4   6.06   147.0   2.890 -108.6\n",
       "6   1  10000    58.4  15.40    60.0  15.400   -1.6\n",
       "7   2     10    13.1   2.36    12.1   0.837    1.0\n",
       "8   2     32    14.5   1.12    15.2   0.824   -0.7\n",
       "9   2    100    20.1   1.39    22.3   1.500   -2.2\n",
       "10  2    316    23.1   2.73    23.9   2.300   -0.8\n",
       "11  2   1000    26.7   3.00    72.0   7.140  -45.3\n",
       "12  2   3162    33.1   7.06    35.0   7.480   -1.9\n",
       "13  2  10000    60.0  16.60     NaN     NaN    NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df['diff'] = comp_df['mean_x']-comp_df['mean_y']\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc458631-f6e8-4edc-8d4d-b15fb739e3e8",
   "metadata": {},
   "source": [
    "We note a few things here. Firstly, negative differences represent when the separate notebooks produced faster runtimes than individual one. Secondly, when we calculated runtimes in the individual notebook, it alternated in order between nodes and p's. Concretely, we had the order: \n",
    "\n",
    "`10 1, 32 2, 100 1, 316 2, 1000 1, 3162 2, 10000 1, 10 2, 32 1, 100 2, 316 1, 1000 2, 3162 1, 10000 2`\n",
    "\n",
    "What this means is that for `p=1, nodes=10000` the difference between the individual and the separate notebook methods was minimal `(-1.9s)`, since it was still the 7th calculated runtime in both notebooks. However, note that `p=2, nodes=3162` is significantly slower in the individual notebook `(-108.6s)` as this was the the 13th runtime in the individual notebook, but only the 6th in the separate notebook. We can also conclude this difference to be significant because the standard deviation for the corresponding run in both methods is much lower, and so this is not just an issue of runtime variance. The same can be seen for `p=1, nodes=316` and `p=2, nodes=1000`.\n",
    "\n",
    "This confirms that for some reason, PySpark runtimes seem to get slower as more runs are carried out. The specific reasons for this are unclear to us, though if we look back at the `WinError 10054` error that was raised, we surmise that a connection to apache.spark.org is timing out and slowing down and so are the runtimes as a result of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c04d1c-e9f5-4898-aeb3-1d942b0b4b93",
   "metadata": {},
   "source": [
    "Finally, we compare numbers for L=3,R=2 and L=2,R=2 from the separate notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf4c91ed-ec86-4343-9720-3b49d1f6491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_times_df_2 = pd.read_csv('../Data/p1_times_2.csv',index_col='Unnamed: 0')\n",
    "p2_times_df_2 = pd.read_csv('../Data/p2_times_2.csv',index_col='Unnamed: 0')\n",
    "times_df_2 = pd.concat([p1_times_df_2,p2_times_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2876b64c-fe36-4d43-ac71-e3a3e616dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3162</td>\n",
       "      <td>38.4</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>58.4</td>\n",
       "      <td>15.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>26.7</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3162</td>\n",
       "      <td>33.1</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p  nodes  mean     sd\n",
       "0   1     10  13.2   2.53\n",
       "1   1     32  18.3   1.13\n",
       "2   1    100  21.1   1.18\n",
       "3   1    316  24.2   2.44\n",
       "4   1   1000  25.9   2.86\n",
       "5   1   3162  38.4   6.06\n",
       "6   1  10000  58.4  15.40\n",
       "7   2     10  13.1   2.36\n",
       "8   2     32  14.5   1.12\n",
       "9   2    100  20.1   1.39\n",
       "10  2    316  23.1   2.73\n",
       "11  2   1000  26.7   3.00\n",
       "12  2   3162  33.1   7.06\n",
       "13  2  10000  60.0  16.60"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfb8db79-66dd-49ff-8bfb-2926aa0c7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3162</td>\n",
       "      <td>36.3</td>\n",
       "      <td>4.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>5.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>23.6</td>\n",
       "      <td>1.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>26.4</td>\n",
       "      <td>2.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3162</td>\n",
       "      <td>31.4</td>\n",
       "      <td>4.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p  nodes  mean     sd\n",
       "0  1     10  12.5  1.940\n",
       "1  1     32  18.1  0.780\n",
       "2  1    100  19.5  1.290\n",
       "3  1    316  21.7  1.200\n",
       "4  1   1000  24.2  2.110\n",
       "5  1   3162  36.3  4.090\n",
       "6  1  10000  94.0  5.930\n",
       "0  2     10  15.5  3.150\n",
       "1  2     32  14.7  1.260\n",
       "2  2    100  20.1  0.683\n",
       "3  2    316  23.6  1.620\n",
       "4  2   1000  26.4  2.870\n",
       "5  2   3162  31.4  4.970\n",
       "6  2  10000  70.0  0.764"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0158a193-2032-45ef-bd73-d1c714b294ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>nodes</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>sd_x</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>sd_y</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2.53</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1.940</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.13</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1.18</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.44</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1.200</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2.86</td>\n",
       "      <td>24.2</td>\n",
       "      <td>2.110</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3162</td>\n",
       "      <td>38.4</td>\n",
       "      <td>6.06</td>\n",
       "      <td>36.3</td>\n",
       "      <td>4.090</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>58.4</td>\n",
       "      <td>15.40</td>\n",
       "      <td>94.0</td>\n",
       "      <td>5.930</td>\n",
       "      <td>-35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13.1</td>\n",
       "      <td>2.36</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.150</td>\n",
       "      <td>-2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.12</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.260</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>20.1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>316</td>\n",
       "      <td>23.1</td>\n",
       "      <td>2.73</td>\n",
       "      <td>23.6</td>\n",
       "      <td>1.620</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>26.7</td>\n",
       "      <td>3.00</td>\n",
       "      <td>26.4</td>\n",
       "      <td>2.870</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3162</td>\n",
       "      <td>33.1</td>\n",
       "      <td>7.06</td>\n",
       "      <td>31.4</td>\n",
       "      <td>4.970</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>-10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p  nodes  mean_x   sd_x  mean_y   sd_y  diff\n",
       "0   1     10    13.2   2.53    12.5  1.940   0.7\n",
       "1   1     32    18.3   1.13    18.1  0.780   0.2\n",
       "2   1    100    21.1   1.18    19.5  1.290   1.6\n",
       "3   1    316    24.2   2.44    21.7  1.200   2.5\n",
       "4   1   1000    25.9   2.86    24.2  2.110   1.7\n",
       "5   1   3162    38.4   6.06    36.3  4.090   2.1\n",
       "6   1  10000    58.4  15.40    94.0  5.930 -35.6\n",
       "7   2     10    13.1   2.36    15.5  3.150  -2.4\n",
       "8   2     32    14.5   1.12    14.7  1.260  -0.2\n",
       "9   2    100    20.1   1.39    20.1  0.683   0.0\n",
       "10  2    316    23.1   2.73    23.6  1.620  -0.5\n",
       "11  2   1000    26.7   3.00    26.4  2.870   0.3\n",
       "12  2   3162    33.1   7.06    31.4  4.970   1.7\n",
       "13  2  10000    60.0  16.60    70.0  0.764 -10.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df_2 = times_df_1.merge(times_df_2, how='left',left_on=['p','nodes'],right_on=['p','nodes'])\n",
    "comp_df_2['diff'] = comp_df_2['mean_x'] - comp_df_2['mean_y']\n",
    "comp_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80e9c0-3a87-4b2e-a227-f29ecf3c410b",
   "metadata": {},
   "source": [
    "We note that these runtimes are fairly similar with the main difference being at `nodes=10000` for both `p=1` and `p=2`. This further confirms that as more runs are made, the slower PySpark / GraphFrames becomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434b748-06b9-4cf9-82ab-663ec1bec373",
   "metadata": {},
   "source": [
    "As a result, going ahead we will compare the mean runtimes from the L=2, R=2 times coming from the separate notebooks to the R igraph runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa888573-aa91-4e48-9424-6a7b847f1091",
   "metadata": {},
   "source": [
    "## 5.0.4.3 PageRank Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32aa04-95ae-42cb-8b66-2e6d49d4abea",
   "metadata": {},
   "source": [
    "In the above, we performed time calculations for retrieving whether a graph is connected or not. Here, we look at the PageRank algorithm. The page rank looks at the vertices in a graph and how many connections each vertex has. The more connections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cae1728f-3b95-42cd-835c-3d35656c28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1_100 = g1_100.pageRank(resetProbability=0.15, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92c361bc-8001-4c53-b91d-fb3ebd9dd0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|degree|\n",
      "+---+------+\n",
      "| 30|    11|\n",
      "| 71|    10|\n",
      "| 57|    10|\n",
      "| 40|     7|\n",
      "| 64|     7|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g1_100.degrees.sort(col('degree').desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1aaa74aa-6d7a-47d1-a56e-c11a824d7f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+\n",
      "|src|dst|weight|\n",
      "+---+---+------+\n",
      "| 42| 68|   1.0|\n",
      "| 63| 84|   1.0|\n",
      "| 51| 76|   1.0|\n",
      "| 19| 91|   1.0|\n",
      "| 53| 93|   1.0|\n",
      "+---+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr1_100.edges.sort(col('weight').desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b579f60c-8048-473f-abde-970ce4a774f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|          pagerank|\n",
      "+---+------------------+\n",
      "| 84|1.9420931991264179|\n",
      "| 72| 0.483829687978112|\n",
      "| 96|0.7081094438296242|\n",
      "| 48|0.9864705482274984|\n",
      "| 12|0.6010374298908097|\n",
      "+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr1_100.vertices.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad1907-552a-4260-8a32-a08ed102ffb6",
   "metadata": {},
   "source": [
    "PageRank seems to run significantly faster than the method we used for checking whether a graph is connected or not. As a result, we just ran these on separate notebooks (the same Appendix notebooks), with R=10 runs and L=10 loops. We import the results below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac57b846-1f96-4ed4-851e-f8e616bb4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_pr_df = pd.read_csv('../Data/p1_times_pr.csv',index_col='Unnamed: 0')\n",
    "p2_pr_df = pd.read_csv('../Data/p2_times_pr.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a1a8b10-618b-4410-83e0-1c7a8b39b201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>p1_mean</th>\n",
       "      <th>p1_sd</th>\n",
       "      <th>p2_mean</th>\n",
       "      <th>p2_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.235</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.192</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.239</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3162</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.355</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.321</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodes  p1_mean  p1_sd  p2_mean  p2_sd\n",
       "0     10     1.14  0.269     1.26  0.314\n",
       "1     32     1.17  0.225     1.27  0.194\n",
       "2    100     1.24  0.235     1.22  0.292\n",
       "3    316     1.32  0.192     1.23  0.198\n",
       "4   1000     1.40  0.239     1.31  0.237\n",
       "5   3162     1.34  0.355     1.26  0.309\n",
       "6  10000     1.43  0.321     1.34  0.244"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_times_df = p1_pr_df.merge(p2_pr_df,how='left',right_on=['nodes'],left_on=['nodes'])\n",
    "#remove redundant p columns\n",
    "pr_times_df = pr_times_df[['nodes','mean_x','sd_x','mean_y','sd_y']]\n",
    "#rename cols for better readability\n",
    "pr_times_df.columns = ['nodes','p1_mean','p1_sd','p2_mean','p2_sd']\n",
    "pr_times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6727b-3488-4d45-8b69-2112ea8507f9",
   "metadata": {},
   "source": [
    "We can immediately see that these times are consistently lower on average than the component count method that we used previously to assess whether a graph is connected or not. Variability as a percentage of the mean is somewhat high but at the same time, this is in the order of milliseconds which realistically canbe somewhat ignored.\n",
    "\n",
    "Overall, the times do not seem to change regardless of the number of vertices/edges in our graph which is somewhat surprising. We will comment on this more when comparing with R runtimes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56bf2e-eeff-4bf0-ac61-69feb6e83c34",
   "metadata": {},
   "source": [
    "## 5.0.5 R igraph Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da5584-e5a3-46ea-a7bd-56f61b746827",
   "metadata": {},
   "source": [
    "The code for the R Runtimes was largely copy and pasted from the *timing.r* file in the *Bill-Evidence* folder and so it is not explicitly repeated here. Instead it is left in the appendix and the data is imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45b83411-6bdd-4343-aaee-799e6c587007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_comp_time</th>\n",
       "      <th>p2_comp_time</th>\n",
       "      <th>p1_pr_time</th>\n",
       "      <th>p2_pr_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.29</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_comp_time  p2_comp_time  p1_pr_time  p2_pr_time\n",
       "0          0.12          0.13        0.13        0.13\n",
       "1          0.13          0.12        0.17        0.16\n",
       "2          0.14          0.14        0.22        0.22\n",
       "3          0.18          0.19        0.27        0.28\n",
       "4          0.32          0.33        0.48        0.51\n",
       "5          0.76          0.81        1.20        1.22\n",
       "6          2.29          2.48        3.84        3.94"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtimes = pd.read_csv('../Data/naz_rtimes.csv')\n",
    "#convert times from ms to s\n",
    "rtimes = round(rtimes/1000,2)\n",
    "rtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31adfcb-6571-449c-b889-0cd1a073973e",
   "metadata": {},
   "source": [
    "For clarification, R's `microbenchmark` function was used to get these runtimes, which are evaluated over 100 runs each. The times are originally in microseconds rather than seconds, and a mean, median, standard deviation, and quartiles are typically given as a result of running the `microbenchmark` function.\n",
    "\n",
    "Here, we have imported only the median times taken for each algorithm to run, with `p1_comp_time` being the runtime for checking whether the graph is connected for probability `p1` and `p2_pr` being the runtime for PageRank algorithm running on probability `p2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfb2ea-06dc-4711-9583-1e656f4df139",
   "metadata": {},
   "source": [
    "We convert our runtimes to seconds instead of microseconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b386b-af02-4677-b2cb-ace57623bb4f",
   "metadata": {},
   "source": [
    "## 5.0.6 Comparing R and PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d7fcf-9828-4e06-a0e9-777ae1acd6b4",
   "metadata": {},
   "source": [
    "We start off by storing our PySpark runtimes in a similar format to our R times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da9195a2-5d7a-4d61-af05-c7b98c276d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>py_p1_comp</th>\n",
       "      <th>r_p1_comp</th>\n",
       "      <th>py_p2_comp</th>\n",
       "      <th>r_p2_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.18</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.32</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3162</td>\n",
       "      <td>38.4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000</td>\n",
       "      <td>58.4</td>\n",
       "      <td>2.29</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodes  py_p1_comp  r_p1_comp  py_p2_comp  r_p2_comp\n",
       "0     10        13.2       0.12        13.1       0.13\n",
       "1     32        18.3       0.13        14.5       0.12\n",
       "2    100        21.1       0.14        20.1       0.14\n",
       "3    316        24.2       0.18        23.1       0.19\n",
       "4   1000        25.9       0.32        26.7       0.33\n",
       "5   3162        38.4       0.76        33.1       0.81\n",
       "6  10000        58.4       2.29        60.0       2.48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data = {'nodes':nodes,\n",
    "             'py_p1_comp': p1_times_df_1['mean'],\n",
    "             'r_p1_comp': rtimes['p1_comp_time'],\n",
    "             'py_p2_comp':p2_times_df_1['mean'],\n",
    "             'r_p2_comp': rtimes['p2_comp_time']}\n",
    "comp_times = pd.DataFrame(data=comp_data)\n",
    "comp_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb7c73-7ddb-4c25-a3e7-52e1ca9a099b",
   "metadata": {},
   "source": [
    "The difference is very apparent and staggering. R-igraph runs its components function much quickly than PySpark-GraphFrame's method for determining if a graph is connected. One interesting thing to note, however, is the order of magnitude in which runtime slows down by as the number of nodes increases.\n",
    "\n",
    "For p1 times we have an increase from 0.12 to 2.29 seconds in R, a 19x increase in runtime. Whereas for PySpark we see an increase from 13.2 to 58.4 seconds, only a 4.4x increase. This gives us an idea of the scalability of PySpark compared to igraphs. Namely, we expect PySpark to run slower because it is dealing with Resilient Distributed Datasets (RDDs) and so it is performing in a way that may scale better as the number of nodes and edges increase, but faces a large constant in order to that.  \n",
    "\n",
    "Mathematically, we know that R-igraph runs at (or is supposed to run at) $\\mathcal{O}(N)$ where $N = |V|+|E|$, whereas PySpark-GraphFrames may run at $\\mathcal{O}l(og(N^2))$, but the constant, $k_{igraph}$, may be of order $10^2$, while PySpark's constant, $k_{pyspark}$, may be of order $10^4$ (as a vague, not explicit example). These constants are significant when N is small but as N becomes sufficiently large, both these constants become insignificant PySpark should run because of this. At least in theory.\n",
    "\n",
    "Another thing to note is that PySpark working with RDDs means that it has a distinct advantage for larger data sizes as computations can be done over multiple devices which may be cheaper cost-wise than running them all on a single super-device, which would be necessary if running in-memory with R-igraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0a914e-7a3b-4a22-a205-1f79821c9b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>py_p1_pr</th>\n",
       "      <th>r_p1_pr</th>\n",
       "      <th>py_p2_pr</th>\n",
       "      <th>r_p2_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3162</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nodes  py_p1_pr  r_p1_pr  py_p2_pr  r_p2_pr\n",
       "0     10      1.14     0.13      1.26     0.13\n",
       "1     32      1.17     0.17      1.27     0.16\n",
       "2    100      1.24     0.22      1.22     0.22\n",
       "3    316      1.32     0.27      1.23     0.28\n",
       "4   1000      1.40     0.48      1.31     0.51\n",
       "5   3162      1.34     1.20      1.26     1.22\n",
       "6  10000      1.43     3.84      1.34     3.94"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_data = {'nodes':nodes,\n",
    "             'py_p1_pr': p1_pr_df['mean'],\n",
    "             'r_p1_pr': rtimes['p1_pr_time'],\n",
    "             'py_p2_pr':p2_pr_df['mean'],\n",
    "             'r_p2_pr': rtimes['p2_pr_time']}\n",
    "pr_times = pd.DataFrame(data=pr_data)\n",
    "pr_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514193a6-dd45-4e7c-97d3-3583600af12f",
   "metadata": {},
   "source": [
    "Again, we see some interesting results. PySpark-GraphFrames starts off around 10x slower than R-igraph at 10 nodesand ends up being around 2.5x as fast at 10,000 nodes. As mentioned previously, the PySpark-GraphFrame times also remain fairly constant for all number of nodes. This is likely because the order of magnitude of this data is pretty small compared to what PySpark is designed to run at, but this is kind of a hand-wavey argument and we are unsure why it is so constant. \n",
    "\n",
    "However, one thing to note here is that R-igraph runs the `components()` and `page_rank()` functions in a similar way, whereas PySpark-GraphFrames runs them differently. The connectivity of a graph is checked by by returning a dataframe, selecting the relevant components column, then counting distinct instances of components. Creating this dataframe and performing operations on it seems to be the main bottleneck in terms of time complexity. On the other hand, the `pageRank()` function for PySpark-GraphFrames does not strictly return a new dataframe and thus this seems to be much faster and largely constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf867ed-85db-4aef-9e9b-7ed6482fbf0c",
   "metadata": {},
   "source": [
    "## 5.0.7 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62de8b-63f5-460c-a45c-dbd6bf967f95",
   "metadata": {},
   "source": [
    "In this Section 5, we explored algorithms for checking the connectivity of and for performing PageRank on Erdos-Renyi graphs with different probabilities over a different number of nodes using R-igraph and PySpark-GraphFrames. The different probabilities did not seem to make much of a difference here, implying that the number of edges was somewhat less important than the number of nodes. As a result, we did not compare edge count runtimes as it seemed slightly unnecessary to do so, especially given time constraints. Another point to be made is that the number of nodes/edges alone may not be the only factor to affect this and the actual structure of edges is more important (in the sense of what the worst-case scenario would be for each algorithm's specific optimisation approach). Therefore, we stuck to comparing just the number of nodes as that was more readily available.\n",
    "\n",
    "PySpark-GraphFrames seemed to be much slower than R-igraph when it came to checking graph connectivity, and indeed it had some issues with `WinError10054` which we believe is related to some connections made to *apache.spark.org* but we did not have the time to fully understand the reason for this or how to overcome it in a scenario where running multiple commands like this would be necessary. It is noting, however, that as the number of nodes increased, the order of magnitude at which PySpark-GraphFrames slowed down at was smaller than that for R-igraph. This implies that PySpark is faster than R-igraph in terms of Big-O/asymptotic measures, but seems to have a large constant time in comparison. \n",
    "\n",
    "On the other hand, PageRank was much more efficient for PySpark-GraphFrames. The runtime on fewer nodes was longer than that of R-igraph to begin with but this runtime remained fairly constant and ended up being about 2.5x faster than R-igraph in the end on our highest number of nodes (10,000). We conclude that this is due to this PySpark-GraphFrames not having to call on and construct dataframes for this method, as was the case with the connectivity check.\n",
    "\n",
    "Overall, given more time (and better infrastructure) it would have been interesting to explore time complexity more deeply and possibly to look at space and communication complexity. Exploring much larger graphs, possibly ones with more complex structures to see what would happen over an even larger increase of number of nodes would've been fruitful but time and infrastructure did not allow for this. Others methods could have been used to ensure more robust results such as running separate notebooks for R and PySpark and for each individual graph when applying our algorithms. This, however, would've been too cumbersome and possibly unnecessary. Taking into account combination of edge and node counts would have also been interesting, and we did construct a dataframe to count the number of edges for each graph at the beginning but we did not continue on using it for our analysis later on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assessment4env",
   "language": "python",
   "name": "assessment4env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
